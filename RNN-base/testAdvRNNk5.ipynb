{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91e2075f5b553d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:43:21.853458Z",
     "start_time": "2025-05-26T21:42:28.311232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_0.pq    shape=(1974724, 59)\n",
      "train_data_1.pq    shape=(2107305, 59)\n",
      "train_data_10.pq   shape=(2296372, 59)\n",
      "train_data_11.pq   shape=(2450630, 59)\n",
      "train_data_2.pq    shape=(2080508, 59)\n",
      "train_data_3.pq    shape=(2112592, 59)\n",
      "train_data_4.pq    shape=(2064110, 59)\n",
      "train_data_5.pq    shape=(2150908, 59)\n",
      "train_data_6.pq    shape=(2176452, 59)\n",
      "train_data_7.pq    shape=(2222245, 59)\n",
      "train_data_8.pq    shape=(2242615, 59)\n",
      "train_data_9.pq    shape=(2284256, 59)\n",
      "\n",
      "FULL TRAIN shape = (26162717, 59)\n",
      "После merge с target: (26162717, 60)\n",
      "test_data_0.pq     shape=(2389773, 59)\n",
      "test_data_1.pq     shape=(2334828, 59)\n",
      "\n",
      "FULL TEST shape  = (4724601, 59)\n",
      "\n",
      "Train columns: 60\n",
      "Test  columns: 59\n",
      "\n",
      "Пропуски (train):\n",
      "id            0.0\n",
      "rn            0.0\n",
      "enc_col_30    0.0\n",
      "enc_col_31    0.0\n",
      "enc_col_32    0.0\n",
      "enc_col_33    0.0\n",
      "enc_col_34    0.0\n",
      "enc_col_35    0.0\n",
      "enc_col_36    0.0\n",
      "enc_col_37    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "\n",
    "\n",
    "# 1. Пути к данным (относительно корня проекта)\n",
    "\n",
    "DATA_DIR = r'data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train_data')\n",
    "TEST_DIR  = os.path.join(DATA_DIR, 'test_data')\n",
    "\n",
    "TRAIN_PATTERN = os.path.join(TRAIN_DIR, 'train_data_*.pq')\n",
    "TEST_PATTERN  = os.path.join(TEST_DIR,  'test_data_*.pq')\n",
    "\n",
    "# 2. Загрузка train-части\n",
    "\n",
    "train_parts = []\n",
    "for p in sorted(glob.glob(TRAIN_PATTERN)):\n",
    "    df = pd.read_parquet(p)\n",
    "    train_parts.append(df)\n",
    "    print(f'{os.path.basename(p):<18} shape={df.shape}')\n",
    "\n",
    "train = pd.concat(train_parts, ignore_index=True)\n",
    "print(f'\\nFULL TRAIN shape = {train.shape}')\n",
    "\n",
    "target = pd.read_csv(os.path.join(DATA_DIR, 'train_target.csv'))\n",
    "train = train.merge(target, on='id', how='left')\n",
    "print('После merge с target:', train.shape)\n",
    "\n",
    "# 3. Загрузка test-части\n",
    "\n",
    "test_parts = []\n",
    "for p in sorted(glob.glob(TEST_PATTERN)):\n",
    "    df = pd.read_parquet(p)\n",
    "    test_parts.append(df)\n",
    "    print(f'{os.path.basename(p):<18} shape={df.shape}')\n",
    "\n",
    "test = pd.concat(test_parts, ignore_index=True)\n",
    "print(f'\\nFULL TEST shape  = {test.shape}')\n",
    "\n",
    "test_id = test['id'].values\n",
    "\n",
    "# 4. Быстрый sanity-check\n",
    "\n",
    "print('\\nTrain columns:', len(train.columns))\n",
    "print('Test  columns:', len(test.columns))\n",
    "print('\\nПропуски (train):')\n",
    "print(train.isna().mean().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d12c0e1cd40c19a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:46:22.001758Z",
     "start_time": "2025-05-26T21:43:42.782438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "train seqs: 3000000 | test seqs: 500000\n"
     ]
    }
   ],
   "source": [
    "# 5.  Подготовка последовательностей\n",
    "\n",
    "import numpy as np, torch, gc\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ENC_COLS = [c for c in train.columns if c.startswith('enc_col_')]\n",
    "N_FEATS  = len(ENC_COLS)\n",
    "DEVICE   = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE:', DEVICE)\n",
    "\n",
    "train.sort_values(['id', 'rn'], inplace=True)\n",
    "test.sort_values(['id', 'rn'],  inplace=True)\n",
    "\n",
    "def split_sequences(df):\n",
    "    X   = df[ENC_COLS].to_numpy(np.int16) + 1\n",
    "    ids = df['id'].to_numpy(np.int64)\n",
    "    cuts = np.flatnonzero(np.diff(ids)) + 1\n",
    "    seqs = np.split(X, cuts)\n",
    "    ids_unique = ids[np.concatenate(([0], cuts))]\n",
    "    return ids_unique, seqs\n",
    "\n",
    "ids_train, seqs_train = split_sequences(train)\n",
    "ids_test,  seqs_test  = split_sequences(test)\n",
    "\n",
    "y_full = (\n",
    "    train[['id','target']].drop_duplicates()\n",
    "         .set_index('id').loc[ids_train, 'target']\n",
    "         .to_numpy('int8')\n",
    ")\n",
    "\n",
    "n_uniques = (pd.concat([train[ENC_COLS], test[ENC_COLS]]).max() + 2) \\\n",
    "              .astype(int).tolist()\n",
    "\n",
    "print('train seqs:', len(seqs_train), '| test seqs:', len(seqs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f06577ac5abab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:46:37.945428Z",
     "start_time": "2025-05-26T21:46:37.903561Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6.  Dataset\n",
    "\n",
    "class SeqDs(Dataset):\n",
    "    def __init__(self, seqs, labels=None):\n",
    "        self.seqs = [torch.from_numpy(s) for s in seqs]\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32) if labels is not None else None\n",
    "    def __len__(self):  return len(self.seqs)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.seqs[i], self.labels[i]) if self.labels is not None else self.seqs[i]\n",
    "\n",
    "max_idx = torch.tensor([v-1 for v in n_uniques], dtype=torch.long)\n",
    "\n",
    "def collate(batch):\n",
    "    if isinstance(batch[0], tuple):\n",
    "        seqs, labs = zip(*batch)\n",
    "    else:\n",
    "        seqs, labs = batch, None\n",
    "\n",
    "    seqs = [s.unsqueeze(1) if s.ndim == 1 else s for s in seqs]\n",
    "\n",
    "    pad = pad_sequence(seqs, batch_first=True).long()   # [B,T,F]\n",
    "    pad.clamp_max_(max_idx)\n",
    "    return (pad, torch.stack(labs)) if labs is not None else pad"
   ]
  },
  {
   "cell_type": "code",
   "id": "39bca33ebe4ed82",
   "metadata": {},
   "source": [
    "# 7.  Stratified K-fold  +  test DataLoader (num_workers = 0)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "K_FOLDS      = 5\n",
    "BATCH        = 256\n",
    "EPOCHS       = 12\n",
    "PATIENCE     = 2\n",
    "INIT_LR      = 1e-3\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    SeqDs(seqs_test),\n",
    "    batch_size   = BATCH,\n",
    "    shuffle      = False,\n",
    "    collate_fn   = collate,\n",
    "    num_workers  = 0,\n",
    "    pin_memory   = True\n",
    ")\n",
    "\n",
    "oof_pred   = np.zeros(len(ids_train), dtype=np.float32)\n",
    "test_blend = np.zeros(len(ids_test),  dtype=np.float32)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
    "fold_indices = [val_idx for _, val_idx in skf.split(ids_train, y_full)]\n",
    "np.save(\"fold_indices.npy\", np.array(fold_indices, dtype=object))\n",
    "print(\"fold_indices.npy сохранён\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dec49aac58d9854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:38:04.515266Z",
     "start_time": "2025-05-26T22:38:04.497839Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8.  Модель  (Bi-GRU  +  Max- & Avg-pooling)\n",
    "\n",
    "EMB_DIM, HIDDEN = 8, 128\n",
    "class BiGRUPool(nn.Module):\n",
    "    def __init__(self, n_uniques, emb_dim=8, hidden=128):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(n, emb_dim, padding_idx=0) for n in n_uniques])\n",
    "        self.drop = nn.Dropout2d(0.15)\n",
    "        self.gru  = nn.GRU(input_size=emb_dim*N_FEATS, hidden_size=hidden,\n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden*4, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        ein  = torch.cat([e(x[:,:,i]) for i,e in enumerate(self.embs)], dim=-1)\n",
    "        ein  = ein.permute(0,2,1).unsqueeze(3)\n",
    "        ein  = self.drop(ein).squeeze(3).permute(0,2,1)\n",
    "        out, _ = self.gru(ein)\n",
    "        max_p = out.max(dim=1)[0]\n",
    "        avg_p = out.mean(dim=1)\n",
    "        cat   = torch.cat([max_p, avg_p], dim=-1)\n",
    "        return self.head(cat).squeeze(1)\n",
    "\n",
    "model = BiGRUPool(n_uniques, EMB_DIM, HIDDEN).to(DEVICE)\n",
    "opt   = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "lossf = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "549cf87eb8ba6963",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:38:08.677103Z",
     "start_time": "2025-05-26T22:38:08.671535Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_auc(y_true: np.ndarray, y_prob: np.ndarray) -> float:\n",
    "    order = np.argsort(y_prob)\n",
    "    y_true = y_true[order]\n",
    "    n_pos  = y_true.sum()\n",
    "    n_neg  = len(y_true) - n_pos\n",
    "    rank   = np.cumsum(y_true[::-1])[::-1].sum()\n",
    "    return (rank - n_pos*(n_pos+1)/2) / (n_pos*n_neg + 1e-8)\n",
    "\n",
    "def run_epoch(dl, train=True, epoch=0, fold=0):\n",
    "    model.train(train)\n",
    "    mode = 'TRN' if train else 'VAL'\n",
    "    bar  = tqdm(dl, leave=False, desc=f'F{fold} {mode} E{epoch:02d}')\n",
    "\n",
    "    tot, preds, gts = 0.0, [], []\n",
    "    for step, (x, y) in enumerate(bar, 1):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logit = model(x)\n",
    "            loss  = lossf(logit, y)\n",
    "\n",
    "        if train:\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "\n",
    "        tot   += loss.item() * len(x)\n",
    "        preds.append(torch.sigmoid(logit.detach()).cpu())\n",
    "        gts.append(y.cpu())\n",
    "\n",
    "        if step % 200 == 0:\n",
    "            g_np = torch.cat(gts).numpy()\n",
    "            p_np = torch.cat(preds).numpy()\n",
    "            if g_np.min() != g_np.max():\n",
    "                bar.set_postfix({'auc': f'{fast_auc(g_np, p_np):.4f}'})\n",
    "\n",
    "    auc = roc_auc_score(torch.cat(gts).numpy(),\n",
    "                        torch.cat(preds).numpy())\n",
    "    return tot / len(dl.dataset), auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1dd517995a494b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T11:34:29.014971800Z",
     "start_time": "2025-05-26T22:38:28.060128Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─ FOLD 1/5 | train 2400000 | val 600000 ─\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idine\\PycharmProjects\\scientificProject\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961cf740ed9245e4bfd1f08bd5b0cdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "F1 TRN E01:   0%|          | 0/9375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8.  Цикл по K фолдам\n",
    "\n",
    "for fold, (tr_idx, val_idx) in enumerate(skf.split(ids_train, y_full), 1):\n",
    "    print(f\"\\n─ FOLD {fold}/{K_FOLDS} | train {len(tr_idx)} | val {len(val_idx)} ─\")\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        SeqDs([seqs_train[i] for i in tr_idx], y_full[tr_idx]),\n",
    "        batch_size=BATCH, shuffle=True, collate_fn=collate,\n",
    "        num_workers=0, pin_memory=True)\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        SeqDs([seqs_train[i] for i in val_idx], y_full[val_idx]),\n",
    "        batch_size=BATCH, shuffle=False, collate_fn=collate,\n",
    "        num_workers=0, pin_memory=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    model = BiGRUPool(n_uniques, EMB_DIM, HIDDEN).to(DEVICE)\n",
    "    opt   = torch.optim.AdamW(model.parameters(), lr=INIT_LR, weight_decay=1e-2)\n",
    "    scheduler = ReduceLROnPlateau(opt, mode='max',\n",
    "                                  factor=0.5, patience=1,\n",
    "                                  verbose=True, min_lr=1e-5)\n",
    "\n",
    "    BEST, WAIT = 0.0, 0\n",
    "    for ep in range(1, EPOCHS + 1):\n",
    "        run_epoch(train_dl, True,  ep, fold)\n",
    "        _, val_auc = run_epoch(val_dl, False, ep, fold)\n",
    "        scheduler.step(val_auc)\n",
    "        print(f\"F{fold} E{ep:02d} | val_auc={val_auc:.4f} | lr={opt.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        if val_auc > BEST + 1e-4:\n",
    "            BEST, WAIT = val_auc, 0\n",
    "            torch.save(model.state_dict(), f\"best_fold{fold}.pt\")\n",
    "            print(\"checkpoint saved\")\n",
    "        else:\n",
    "            WAIT += 1\n",
    "            if WAIT >= PATIENCE:\n",
    "                print(\"   early-stop\"); break\n",
    "\n",
    "    model.load_state_dict(torch.load(f\"best_fold{fold}.pt\", map_location=DEVICE))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = torch.cat([\n",
    "            torch.sigmoid(model(xb.to(DEVICE))).cpu()\n",
    "            for xb, _ in val_dl]).numpy()\n",
    "    oof_pred[val_idx] = val_pred\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_pred = torch.cat([\n",
    "            torch.sigmoid(model(xb.to(DEVICE))).cpu()\n",
    "            for xb in test_dl]).numpy()\n",
    "    test_blend += test_pred / K_FOLDS\n",
    "\n",
    "    torch.save({\n",
    "        \"state_dict\": torch.load(f\"best_fold{fold}.pt\", map_location=\"cpu\"),\n",
    "        \"val_idx\"  : val_idx,\n",
    "        \"val_pred\" : val_pred.astype('float32'),\n",
    "        \"test_pred\": test_pred.astype('float32'),\n",
    "        \"config\"   : {\"emb_dim\": EMB_DIM,\n",
    "                      \"hidden\" : HIDDEN,\n",
    "                      \"n_uniques\": n_uniques,\n",
    "                      \"fold\": fold}\n",
    "    }, f\"gru_fold{fold}.pth\")\n",
    "    print(f\"gru_fold{fold}.pth сохранён  (best val_auc {BEST:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776f0ba0e1c61ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL OOF ROC-AUC = 0.78134\n",
      "submission_gru_kfold.csv готов: (500000, 2)\n"
     ]
    }
   ],
   "source": [
    "# 9.  Итоговый OOF-AUC  +  submission\n",
    "\n",
    "full_auc = roc_auc_score(y_full, oof_pred)\n",
    "print(f\"\\nFULL OOF ROC-AUC = {full_auc:.5f}\")\n",
    "\n",
    "sample = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\n",
    "sample[\"target\"] = pd.Series(test_blend, index=ids_test).reindex(sample[\"id\"]).values.astype('float32')\n",
    "sample.to_csv(\"submission_gru_kfold.csv\", index=False)\n",
    "print(\"submission_gru_kfold.csv готов:\", sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee5599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
